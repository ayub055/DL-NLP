{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "259efd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-17 10:27:33.469941: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-17 10:27:33.928510: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-17 10:27:34.442720: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-17 10:27:34.442984: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Collecting en-core-web-md==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from en-core-web-md==3.5.0) (3.5.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.4.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /data/home/ayyoobmohd/miniconda3/envs/DL/lib/python3.11/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch\n",
    "#!pip install torchtext\n",
    "#!pip install openpyxl\n",
    "#!pip install nltk\n",
    "#!pip install spacy\n",
    "!python -m spacy download en_core_web_md "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a62d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /data/home/ayyoobmohd/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /data/home/ayyoobmohd/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82589959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 10:27:43.660172: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-17 10:27:44.185662: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-17 10:27:44.639302: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-17 10:27:44.639624: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import spacy\n",
    "from torchtext.vocab import GloVe, FastText\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2169a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('/data/home/ayyoobmohd/DLNLP/Glove-and-Sentiments/Datasets/ClassificationDataset1.xlsx')\n",
    "#/data/home/ayyoobmohd/DLNLP/Glove-and-Sentiments/Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dd3f1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Negative Review  \\\n",
      "0  I am so angry that i made this post available ...   \n",
      "1                                        No Negative   \n",
      "2   Rooms are nice but for elderly a bit difficul...   \n",
      "3   My room was dirty and I was afraid to walk ba...   \n",
      "4  You When I booked with your company on line yo...   \n",
      "\n",
      "                                     Positive Review  \n",
      "0   Only the park outside of the hotel was beauti...  \n",
      "1   No real complaints the hotel was great great ...  \n",
      "2   Location was good and staff were ok It is cut...  \n",
      "3   Great location in nice surroundings the bar a...  \n",
      "4    Amazing location and building Romantic setting   \n",
      "(8999, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data.head(5))\n",
    "print(data.shape)\n",
    "#df = df.head(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144f6a3a",
   "metadata": {},
   "source": [
    "## Download Glove vectors and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bfa6311",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_vectors = GloVe(name='840B', dim=300)\n",
    "fasttext = FastText(language=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "503745f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile data_loader.py\n",
    "## Declaring Path \n",
    "#/data/home/ayyoobmohd/DLNLP/Glove-and-Sentiments/Datasets/ClassificationDataset1.xlsx\n",
    "pos_path = '/data/home/ayyoobmohd/DLNLP/Glove-and-Sentiments/data/positive_reviews.csv'\n",
    "neg_path = '/data/home/ayyoobmohd/DLNLP/Glove-and-Sentiments/data/negative_reviews.csv'\n",
    "\n",
    "def making_new_dataset(data):\n",
    "    data.to_csv(pos_path, index = False, header= False,\n",
    "          encoding = \"latin-1\", columns = ['Positive Review'])\n",
    "    \n",
    "    data.to_csv(neg_path, index = False, header= False,\n",
    "          encoding = \"latin-1\", columns = ['Negative Review'])\n",
    "    \n",
    "    \n",
    "    positive_set = open(pos_path, \"r\", encoding=\"latin-1\").read()\n",
    "    negative_set = open(neg_path, \"r\", encoding=\"latin-1\").read()\n",
    "    \n",
    "    pos_set = positive_set.split(\"\\n\")[:-1]\n",
    "    neg_set = negative_set.split(\"\\n\")[:-1]\n",
    "    \n",
    "    #print(len(positive_data), len(negative_data))\n",
    "    \n",
    "    return pos_set, neg_set\n",
    "\n",
    "positive_data, negative_data = making_new_dataset(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8b17617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ReviewsText(data, mode='positive'):\n",
    "    \n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "    data_set = []\n",
    "    vocabulary = {}\n",
    "    chars_to_remove = ['--', '`', '~', '<', '>', '*', '{', '}', '^', '=', '_', '[', ']', '|', '- ', '.', ',']\n",
    "    \n",
    "    if mode == 'positive':\n",
    "        sentiment = 1\n",
    "    else :\n",
    "        sentiment = 0\n",
    "    \n",
    "    for i, v in enumerate(data):\n",
    "\n",
    "            # Removing Un-necessary symbols in our sentence\n",
    "            for chars in chars_to_remove:\n",
    "                v = v.replace(chars, \" \", -1)\n",
    "\n",
    "            sentence = torch.zeros(600)\n",
    "            n = 0\n",
    "            for token in nlp(v): \n",
    "\n",
    "                sentence[:300] += global_vectors.get_vecs_by_tokens(token.text, lower_case_backup=True)\n",
    "                sentence[300:] += fasttext.get_vecs_by_tokens(token.text, lower_case_backup=True).squeeze(dim=0)\n",
    "                n += 1\n",
    "\n",
    "            # Taking mean\n",
    "            sentence = sentence / n\n",
    "            data_set.append((sentence, sentiment))\n",
    "    \n",
    "    return data_set     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bc73eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of positive reviews : 8999 || Length of positive reviews : 8999\n",
      "Length of Complete concatenated Dataset of reviews : 17998\n"
     ]
    }
   ],
   "source": [
    "pos = preprocess_ReviewsText(positive_data, 'positive')\n",
    "neg = preprocess_ReviewsText(negative_data, 'negative')\n",
    "data = pos + neg\n",
    "print(f\"Length of positive reviews : {len(pos)} || Length of positive reviews : {len(neg)}\")\n",
    "print(f\"Length of Complete concatenated Dataset of reviews : {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9951bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('temp.txt', 'w') as fp:\n",
    "#     fp.write('\\n'.join('%s %s' % x for x in data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881cbf6b",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dc8c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile utils.py\n",
    "def set_seed(seed = 42):\n",
    "    '''\n",
    "        For Reproducibility: Sets the seed of the entire notebook.\n",
    "    '''\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # Sets a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "def split_indices(num_values, percentage):\n",
    "\n",
    "    # Determine size of Validation set\n",
    "    val_size = int(percentage * num_values)\n",
    "\n",
    "    # Create random permutation of 0 to num_values-1\n",
    "    idxs = np.random.permutation(num_values)\n",
    "    return idxs[val_size:], idxs[:val_size]\n",
    "\n",
    "set_seed(1)\n",
    "train_pos_indices, val_pos_indices = split_indices(len(positive_data), 0.1)\n",
    "train_neg_indices, val_neg_indices = split_indices(len(negative_data), 0.1)\n",
    "\n",
    "train_indices = np.concatenate((train_pos_indices, train_neg_indices+len(positive_data)-1))\n",
    "val_indices = np.concatenate((val_pos_indices, val_neg_indices+len(positive_data)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3c43405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1798, 16200)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_indices), len(train_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8684c0ff",
   "metadata": {},
   "source": [
    "## Data Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c18481de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile utils.py\n",
    "def batch_fn(instn):\n",
    "\n",
    "    sentence = torch.zeros(len(instn), 600)\n",
    "\n",
    "    for i, v in enumerate(instn):\n",
    "        sentence[i] = v[0]\n",
    "\n",
    "    labels = torch.Tensor([x[1] for x in instn])\n",
    "\n",
    "    return (sentence, labels)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_sampler   = SubsetRandomSampler(train_indices)\n",
    "train_loader    = DataLoader(data, batch_size, sampler=train_sampler, collate_fn=batch_fn)\n",
    "\n",
    "val_sampler     = SubsetRandomSampler(val_indices)\n",
    "val_loader      = DataLoader(data, batch_size, sampler=val_sampler, collate_fn=batch_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2ac805",
   "metadata": {},
   "source": [
    "# Models : DAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7942543",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c8f5acd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDAN\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class DAN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(600, 1024)\n",
    "        self.linear2 = nn.Linear(1024, 2048)\n",
    "        self.linear3 = nn.Linear(2048, 512)\n",
    "        self.linear4 = nn.Linear(512, 64)\n",
    "        self.linear5 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, Xb, tsne = False):\n",
    "        x = self.linear1(Xb)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x) \n",
    "        x = self.linear3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear4(x)\n",
    "        \n",
    "        if tsne == True:\n",
    "            return x\n",
    "            \n",
    "        x = F.relu(x)\n",
    "        x = self.linear5(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1398b9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DAN()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "loss_fn = F.binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adb1bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bd47baf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from helper_functions import plot_predictions, plot_decision_boundary, accuracy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ed51f78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 445.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1  Training Loss:  69.30224609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1491.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  5.182392597198486\n",
      "Validation accuracy:  0.9327030033370411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 800.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2  Training Loss:  44.79571533203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1607.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  5.104466915130615\n",
      "Validation accuracy:  0.9343715239154616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 791.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3  Training Loss:  39.6877555847168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1669.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  4.939173221588135\n",
      "Validation accuracy:  0.9382647385984427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 787.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4  Training Loss:  36.58692169189453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1707.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  4.81107234954834\n",
      "Validation accuracy:  0.9365962180200222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 769.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5  Training Loss:  34.09595489501953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1691.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  5.006438732147217\n",
      "Validation accuracy:  0.9410456062291435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 801.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6  Training Loss:  32.08406448364258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1401.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  5.043338775634766\n",
      "Validation accuracy:  0.9354838709677419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 785.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7  Training Loss:  29.650548934936523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1430.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  5.154064655303955\n",
      "Validation accuracy:  0.9421579532814238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 805.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8  Training Loss:  28.457361221313477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1637.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  5.079061508178711\n",
      "Validation accuracy:  0.9449388209121246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 787.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9  Training Loss:  25.954675674438477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1707.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  5.203518390655518\n",
      "Validation accuracy:  0.9382647385984427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 793.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10  Training Loss:  24.673669815063477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1437.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  5.115695476531982\n",
      "Validation accuracy:  0.9416017797552837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 787.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11  Training Loss:  23.90966033935547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1603.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  5.197197914123535\n",
      "Validation accuracy:  0.9388209121245829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 472.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12  Training Loss:  21.773103713989258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1626.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  6.209021091461182\n",
      "Validation accuracy:  0.9327030033370411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 748.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13  Training Loss:  20.886354446411133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1368.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  5.648735046386719\n",
      "Validation accuracy:  0.942714126807564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 756.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  14  Training Loss:  18.311288833618164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1702.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  6.243546962738037\n",
      "Validation accuracy:  0.9443826473859844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 781.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  15  Training Loss:  17.604734420776367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1697.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  5.542281150817871\n",
      "Validation accuracy:  0.9421579532814238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 793.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16  Training Loss:  17.30828285217285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1709.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  5.947999000549316\n",
      "Validation accuracy:  0.9449388209121246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 789.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  17  Training Loss:  16.030742645263672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1704.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  5.999490737915039\n",
      "Validation accuracy:  0.9410456062291435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 781.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  18  Training Loss:  14.291221618652344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1435.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  6.68242883682251\n",
      "Validation accuracy:  0.9421579532814238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 793.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19  Training Loss:  13.431424140930176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1705.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  7.287652492523193\n",
      "Validation accuracy:  0.9365962180200222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 779.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  20  Training Loss:  12.97905158996582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1704.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  7.025003910064697\n",
      "Validation accuracy:  0.9443826473859844\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 786.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  21  Training Loss:  11.838408470153809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1415.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  7.117300033569336\n",
      "Validation accuracy:  0.9438264738598443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 776.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  22  Training Loss:  10.930962562561035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1697.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  7.871668815612793\n",
      "Validation accuracy:  0.9410456062291435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 783.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  23  Training Loss:  14.022547721862793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1700.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  7.981631278991699\n",
      "Validation accuracy:  0.9399332591768632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 784.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  24  Training Loss:  10.703930854797363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1700.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  8.328694343566895\n",
      "Validation accuracy:  0.9399332591768632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 466.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  25  Training Loss:  9.107155799865723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 1699.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  7.744479656219482\n",
      "Validation accuracy:  0.9371523915461624\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_epoch = 25\n",
    "\n",
    "best_test_acc = 0\n",
    "for ep in range(max_epoch):\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for xb, yb in tqdm(train_loader):\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        y_hat = model(xb)\n",
    "\n",
    "        loss = loss_fn(y_hat.squeeze(), yb)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        epoch_loss += loss\n",
    "\n",
    "    print(\"Epoch: \", ep+1, \" Training Loss: \", epoch_loss.item())\n",
    "    \n",
    "    #----------- Validation -----------\n",
    "\n",
    "    val_labels = []\n",
    "    val_pred = []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_epoch_loss = 0\n",
    "\n",
    "    for xb, yb in tqdm(val_loader):\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        y_hat = model(xb)\n",
    "\n",
    "        loss = loss_fn(y_hat.squeeze(), yb)\n",
    "\n",
    "        val_epoch_loss += loss\n",
    "\n",
    "        val_labels.extend(yb.cpu().detach().numpy())\n",
    "        val_pred.extend(y_hat.round().cpu().detach().numpy())\n",
    "\n",
    "    print(\"Validation loss: \", val_epoch_loss.item())\n",
    "    print(\"Validation accuracy: \", accuracy_score(val_labels, val_pred))\n",
    "\n",
    "\n",
    "    if ep > 15 and prev_val_loss - val_epoch_loss.item() > 0.05:\n",
    "        print(\"Saving Model\")\n",
    "        torch.save(model.state_dict(), \"DAN_model1.pt\")\n",
    "    \n",
    "    prev_val_loss = val_epoch_loss.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d883506",
   "metadata": {},
   "source": [
    "## Model : LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2ef15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import get_tokenizer\n",
    "global_vectors = GloVe(name='840B', dim=300)\n",
    "\n",
    "def preprocess_tokenized_reviewText(pos, neg):\n",
    "    \n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "    data_set = []\n",
    "    vocab = []\n",
    "    chars_to_remove = ['--', '`', '~', '<', '>', '*', '{', '}', '^', '=', '_', '[', ']', '|', '- ', '.', ',']\n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "    \n",
    "    for line in pos:\n",
    "        # Tokenizes the input text into words\n",
    "        tokens = tokenizer(line)\n",
    "\n",
    "        data_set.append((tokens, 1))\n",
    "        # Adds the extracted words to a list\n",
    "        vocab.extend(tokens)\n",
    "    print(f\"--- Positive Finished ---\")\n",
    "    \n",
    "    for line in neg:\n",
    "        # Tokenizes the input text into words\n",
    "        tokens = tokenizer(line)\n",
    "\n",
    "        data_set.append((tokens, 0))\n",
    "        # Adds the extracted words to a list\n",
    "        vocab.extend(tokens)\n",
    "    print(f\"--- Negative Finished ---\")\n",
    "    \n",
    "    # Stores all the unique words in the dataset and their frequencies\n",
    "    vocabulary = {}\n",
    "\n",
    "    # Calculates the frequency of each unique word in the vocabulary\n",
    "    for word in vocab:\n",
    "        if word in vocabulary:\n",
    "            vocabulary[word] += 1\n",
    "        else:\n",
    "            vocabulary[word] = 1\n",
    "\n",
    "    print(\"Number of unique words in the vocabulary: \", len(vocabulary))\n",
    "    return data_set, vocabulary\n",
    "\n",
    "#-----------------------------------------------------------------------------------#\n",
    "\n",
    "#len(set(vocab))\n",
    "def sort_key(s):\n",
    "    return len(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b66b78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Positive Finished ---\n",
      "--- Negative Finished ---\n",
      "Number of unique words in the vocabulary:  10421\n",
      "Length of Complete concatenated Dataset of reviews : 17998\n"
     ]
    }
   ],
   "source": [
    "data, vocabulary = preprocess_tokenized_reviewText(positive_data, negative_data)\n",
    "print(f\"Length of Complete concatenated Dataset of reviews : {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f758a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = sorted(data, key=sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86e3b722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'only': 0,\n",
       " 'the': 1,\n",
       " 'park': 2,\n",
       " 'outside': 3,\n",
       " 'of': 4,\n",
       " 'hotel': 5,\n",
       " 'was': 6,\n",
       " 'beautiful': 7,\n",
       " 'no': 8,\n",
       " 'real': 9,\n",
       " 'complaints': 10,\n",
       " 'great': 11,\n",
       " 'location': 12,\n",
       " 'surroundings': 13,\n",
       " 'rooms': 14,\n",
       " 'amenities': 15,\n",
       " 'and': 16,\n",
       " 'service': 17,\n",
       " 'two': 18,\n",
       " 'recommendations': 19,\n",
       " 'however': 20,\n",
       " 'firstly': 21,\n",
       " 'staff': 22,\n",
       " 'upon': 23,\n",
       " 'check': 24,\n",
       " 'in': 25,\n",
       " 'are': 26,\n",
       " 'very': 27,\n",
       " 'confusing': 28,\n",
       " 'regarding': 29,\n",
       " 'deposit': 30,\n",
       " 'payments': 31,\n",
       " 'offer': 32,\n",
       " 'you': 33,\n",
       " 'checkout': 34,\n",
       " 'to': 35,\n",
       " 'refund': 36,\n",
       " 'your': 37,\n",
       " 'original': 38,\n",
       " 'payment': 39,\n",
       " 'can': 40,\n",
       " 'make': 41,\n",
       " 'a': 42,\n",
       " 'new': 43,\n",
       " 'one': 44,\n",
       " 'bit': 45,\n",
       " 'secondly': 46,\n",
       " 'on': 47,\n",
       " 'site': 48,\n",
       " 'restaurant': 49,\n",
       " 'is': 50,\n",
       " 'lacking': 51,\n",
       " 'well': 52,\n",
       " 'thought': 53,\n",
       " 'out': 54,\n",
       " 'excellent': 55,\n",
       " 'quality': 56,\n",
       " 'food': 57,\n",
       " 'for': 58,\n",
       " 'anyone': 59,\n",
       " 'vegetarian': 60,\n",
       " 'or': 61,\n",
       " 'vegan': 62,\n",
       " 'background': 63,\n",
       " 'but': 64,\n",
       " 'even': 65,\n",
       " 'wrap': 66,\n",
       " 'toasted': 67,\n",
       " 'sandwich': 68,\n",
       " 'option': 69,\n",
       " 'would': 70,\n",
       " 'be': 71,\n",
       " 'aside': 72,\n",
       " 'from': 73,\n",
       " 'those': 74,\n",
       " 'minor': 75,\n",
       " 'things': 76,\n",
       " 'fantastic': 77,\n",
       " 'spot': 78,\n",
       " 'will': 79,\n",
       " 'back': 80,\n",
       " 'when': 81,\n",
       " 'i': 82,\n",
       " 'return': 83,\n",
       " 'amsterdam': 84,\n",
       " 'good': 85,\n",
       " 'were': 86,\n",
       " 'ok': 87,\n",
       " 'it': 88,\n",
       " 'cute': 89,\n",
       " 'breakfast': 90,\n",
       " 'range': 91,\n",
       " 'nice': 92,\n",
       " 'go': 93,\n",
       " 'bar': 94,\n",
       " 'have': 95,\n",
       " 'lovely': 96,\n",
       " 'outdoor': 97,\n",
       " 'area': 98,\n",
       " 'building': 99,\n",
       " 'also': 100,\n",
       " 'has': 101,\n",
       " 'quite': 102,\n",
       " 'some': 103,\n",
       " 'character': 104,\n",
       " 'amazing': 105,\n",
       " 'romantic': 106,\n",
       " 'setting': 107,\n",
       " 'with': 108,\n",
       " 'modern': 109,\n",
       " 'design': 110,\n",
       " 'chill': 111,\n",
       " 'place': 112,\n",
       " 'nearby': 113,\n",
       " 'awesome': 114,\n",
       " 'main': 115,\n",
       " 'stairs': 116,\n",
       " 'room': 117,\n",
       " 'spacious': 118,\n",
       " 'bright': 119,\n",
       " 'located': 120,\n",
       " 'quiet': 121,\n",
       " 'set': 122,\n",
       " 'friendly': 123,\n",
       " 'high': 124,\n",
       " 'we': 125,\n",
       " 'oth': 126,\n",
       " 'enjoyed': 127,\n",
       " 'positive': 128,\n",
       " 'big': 129,\n",
       " 'enough': 130,\n",
       " 'bed': 131,\n",
       " 'there': 132,\n",
       " 'which': 133,\n",
       " 'walk': 134,\n",
       " 'morning': 135,\n",
       " 'evening': 136,\n",
       " 'many': 137,\n",
       " 'people': 138,\n",
       " 'having': 139,\n",
       " 'picnics': 140,\n",
       " 'do': 141,\n",
       " 'bicycling': 142,\n",
       " 'stunningly': 143,\n",
       " 'decorated': 144,\n",
       " 'really': 145,\n",
       " 'top': 146,\n",
       " 'pictures': 147,\n",
       " '300': 148,\n",
       " 'true': 149,\n",
       " 'beauty': 150,\n",
       " 'been': 151,\n",
       " 'kept': 152,\n",
       " 'modernised': 153,\n",
       " 'brilliantly': 154,\n",
       " 'bath': 155,\n",
       " 'inviting': 156,\n",
       " 'more': 157,\n",
       " 'couples': 158,\n",
       " 'menu': 159,\n",
       " 'pricey': 160,\n",
       " 'loads': 161,\n",
       " 'little': 162,\n",
       " 'eatery': 163,\n",
       " 'places': 164,\n",
       " 'within': 165,\n",
       " 'walking': 166,\n",
       " 'distance': 167,\n",
       " 'tram': 168,\n",
       " 'stop': 169,\n",
       " 'into': 170,\n",
       " 'centre': 171,\n",
       " 'about': 172,\n",
       " '6': 173,\n",
       " 'minute': 174,\n",
       " 'away': 175,\n",
       " '3': 176,\n",
       " '4': 177,\n",
       " 'stops': 178,\n",
       " 'recommend': 179,\n",
       " 'this': 180,\n",
       " 's': 181,\n",
       " 'unbelievably': 182,\n",
       " 'priced': 183,\n",
       " 'too': 184,\n",
       " 'style': 185,\n",
       " 'comfy': 186,\n",
       " 'being': 187,\n",
       " 'renovated': 188,\n",
       " 'care': 189,\n",
       " 'an': 190,\n",
       " 'appreciation': 191,\n",
       " 'its': 192,\n",
       " 'unique': 193,\n",
       " 'structure': 194,\n",
       " 'my': 195,\n",
       " 'comfortable': 196,\n",
       " 'had': 197,\n",
       " 'large': 198,\n",
       " 'double': 199,\n",
       " 'paned': 200,\n",
       " 'glass': 201,\n",
       " 'window': 202,\n",
       " 'onto': 203,\n",
       " 'lush': 204,\n",
       " 'greenery': 205,\n",
       " 'selection': 206,\n",
       " 'spectacular': 207,\n",
       " 'all': 208,\n",
       " 'considered': 209,\n",
       " 'price': 210,\n",
       " 'plan': 211,\n",
       " 'historic': 212,\n",
       " 'that': 213,\n",
       " 'why': 214,\n",
       " 'chose': 215,\n",
       " 'took': 216,\n",
       " 'sincirely': 217,\n",
       " 'because': 218,\n",
       " 'cheaper': 219,\n",
       " 'seem': 220,\n",
       " 'hold': 221,\n",
       " 'church': 222,\n",
       " 'close': 223,\n",
       " 'arrive': 224,\n",
       " 'city': 225,\n",
       " 'like': 226,\n",
       " '10': 227,\n",
       " 'minutes': 228,\n",
       " 'by': 229,\n",
       " 'super': 230,\n",
       " 'easy': 231,\n",
       " 'inside': 232,\n",
       " 'cool': 233,\n",
       " 'incredible': 234,\n",
       " 'floor': 235,\n",
       " 'up': 236,\n",
       " 'll': 237,\n",
       " 'come': 238,\n",
       " 'sure': 239,\n",
       " 'gentle': 240,\n",
       " 'spanish': 241,\n",
       " 'man': 242,\n",
       " 'onsite': 243,\n",
       " 'cafe': 244,\n",
       " 'bobby': 245,\n",
       " 'gin': 246,\n",
       " 'tonic': 247,\n",
       " 'loved': 248,\n",
       " 'fact': 249,\n",
       " 'busy': 250,\n",
       " 'dam': 251,\n",
       " 'square': 252,\n",
       " 'system': 253,\n",
       " 'brilliant': 254,\n",
       " 'handle': 255,\n",
       " 'helpful': 256,\n",
       " 'familiarized': 257,\n",
       " 'themselves': 258,\n",
       " 'us': 259,\n",
       " 'they': 260,\n",
       " 'realized': 261,\n",
       " 'travelled': 262,\n",
       " 'ireland': 263,\n",
       " 'public': 264,\n",
       " 'areas': 265,\n",
       " 'broken': 266,\n",
       " 'drains': 267,\n",
       " 'bathroom': 268,\n",
       " 'smelt': 269,\n",
       " 'old': 270,\n",
       " 'clearly': 271,\n",
       " 'issues': 272,\n",
       " 'liked': 273,\n",
       " 'hotels': 274,\n",
       " 'history': 275,\n",
       " 'such': 276,\n",
       " 'enormous': 277,\n",
       " 't': 278,\n",
       " 'imagine': 279,\n",
       " 'how': 280,\n",
       " 'girls': 281,\n",
       " 'orphaned': 282,\n",
       " 'their': 283,\n",
       " 'quirky': 284,\n",
       " 'mix': 285,\n",
       " 'fruits': 286,\n",
       " 'pastries': 287,\n",
       " 'meats': 288,\n",
       " 'fish': 289,\n",
       " 'breads': 290,\n",
       " 'regular': 291,\n",
       " 'bacon': 292,\n",
       " 'eggs': 293,\n",
       " 'juices': 294,\n",
       " 'tea': 295,\n",
       " 'coffee': 296,\n",
       " 'oostpark': 297,\n",
       " 'few': 298,\n",
       " 'yards': 299,\n",
       " 'continental': 300,\n",
       " 'relaxing': 301,\n",
       " 'element': 302,\n",
       " 'taste': 303,\n",
       " 'health': 304,\n",
       " 'dishes': 305,\n",
       " 'buffet': 306,\n",
       " 'did': 307,\n",
       " 'not': 308,\n",
       " 'try': 309,\n",
       " 'whole': 310,\n",
       " 'view': 311,\n",
       " 'terrace': 312,\n",
       " 'exceptional': 313,\n",
       " 'wedding': 314,\n",
       " 'chapel': 315,\n",
       " 'so': 316,\n",
       " 'convenience': 317,\n",
       " 'just': 318,\n",
       " 'upstairs': 319,\n",
       " 'after': 320,\n",
       " 'party': 321,\n",
       " 'our': 322,\n",
       " 'reason': 323,\n",
       " 'selecting': 324,\n",
       " 'need': 325,\n",
       " '15min': 326,\n",
       " '20min': 327,\n",
       " 'center': 328,\n",
       " 'depends': 329,\n",
       " 'speed': 330,\n",
       " 'locates': 331,\n",
       " 'interior': 332,\n",
       " 'extremely': 333,\n",
       " 'where': 334,\n",
       " 'spoken': 335,\n",
       " 'gave': 336,\n",
       " 'help': 337,\n",
       " 'easiest': 338,\n",
       " 'way': 339,\n",
       " 'relevant': 340,\n",
       " 'transportation': 341,\n",
       " 'tickets': 342,\n",
       " 'locations': 343,\n",
       " 'visit': 344,\n",
       " 'definitely': 345,\n",
       " 'returning': 346,\n",
       " 'as': 347,\n",
       " 'huge': 348,\n",
       " 'stayed': 349,\n",
       " 'split': 350,\n",
       " 'level': 351,\n",
       " 'if': 352,\n",
       " 'difficulty': 353,\n",
       " 'getting': 354,\n",
       " 'request': 355,\n",
       " 'stay': 356,\n",
       " 'oosterpark': 357,\n",
       " 'shops': 358,\n",
       " 'restaurants': 359,\n",
       " 'lots': 360,\n",
       " 'variety': 361,\n",
       " 'choose': 362,\n",
       " 'get': 363,\n",
       " 'metro': 364,\n",
       " '8min': 365,\n",
       " 'short': 366,\n",
       " 'runs': 367,\n",
       " 'station': 368,\n",
       " 'off': 369,\n",
       " '5': 370,\n",
       " 'mins': 371,\n",
       " 'shampoo': 372,\n",
       " 'soap': 373,\n",
       " 'shower': 374,\n",
       " 'facilities': 375,\n",
       " 'than': 376,\n",
       " 'central': 377,\n",
       " 'near': 378,\n",
       " 'museums': 379,\n",
       " 'perfect': 380,\n",
       " 'launch': 381,\n",
       " 'pad': 382,\n",
       " 'day': 383,\n",
       " 'trips': 384,\n",
       " 'former': 385,\n",
       " 'orphanage': 386,\n",
       " 'spread': 387,\n",
       " 'starting': 388,\n",
       " 'right': 389,\n",
       " 'm': 390,\n",
       " 'itself': 391,\n",
       " '5min': 392,\n",
       " 'ride': 393,\n",
       " 'train': 394,\n",
       " 'access': 395,\n",
       " 'everywhere': 396,\n",
       " 'always': 397,\n",
       " 'hand': 398,\n",
       " 'advice': 399,\n",
       " 'wonderful': 400,\n",
       " 'clean': 401,\n",
       " 'beds': 402,\n",
       " 'felt': 403,\n",
       " 'sleeping': 404,\n",
       " 'clouds': 405,\n",
       " 'airy': 406,\n",
       " 'body': 407,\n",
       " 'wash': 408,\n",
       " 'alongside': 409,\n",
       " 'hair': 410,\n",
       " 'dryer': 411,\n",
       " 'towels': 412,\n",
       " 'safe': 413,\n",
       " 'wardrobe': 414,\n",
       " 'hangers': 415,\n",
       " 'clothes': 416,\n",
       " 'holders': 417,\n",
       " 'desk': 418,\n",
       " 'chair': 419,\n",
       " 'fridge': 420,\n",
       " 'kettle': 421,\n",
       " 'cups': 422,\n",
       " 'teas': 423,\n",
       " 'coffees': 424,\n",
       " 'literally': 425,\n",
       " 'everything': 426,\n",
       " 'couldn': 427,\n",
       " 'fault': 428,\n",
       " 'at': 429,\n",
       " 'smell': 430,\n",
       " 'downstairs': 431,\n",
       " 'tennis': 432,\n",
       " 'court': 433,\n",
       " 'pond': 434,\n",
       " 'around': 435,\n",
       " 'concept': 436,\n",
       " 'adjacent': 437,\n",
       " 'gorgeous': 438,\n",
       " 'birds': 439,\n",
       " 'rabbits': 440,\n",
       " 'monastery': 441,\n",
       " 'special': 442,\n",
       " 'mood': 443,\n",
       " 'combined': 444,\n",
       " 'features': 445,\n",
       " 'opposite': 446,\n",
       " 'bakery': 447,\n",
       " 'wifi': 448,\n",
       " 'plus': 449,\n",
       " 'own': 450,\n",
       " 'simply': 451,\n",
       " 'stunning': 452,\n",
       " 'overlooks': 453,\n",
       " 'going': 454,\n",
       " 'through': 455,\n",
       " 'renovations': 456,\n",
       " 'unfortunately': 457,\n",
       " 'means': 458,\n",
       " 'less': 459,\n",
       " 'recognise': 460,\n",
       " 'shortcomings': 461,\n",
       " 'could': 462,\n",
       " 'agreeable': 463,\n",
       " 'possible': 464,\n",
       " 'tub': 465,\n",
       " 'love': 466,\n",
       " 'axcess': 467,\n",
       " 'multiple': 468,\n",
       " 'trams': 469,\n",
       " 'trains': 470,\n",
       " 'manager': 471,\n",
       " 'he': 472,\n",
       " 'upgraded': 473,\n",
       " 'troubles': 474,\n",
       " 'different': 475,\n",
       " 'feel': 476,\n",
       " 'welcome': 477,\n",
       " 'directly': 478,\n",
       " 'front': 479,\n",
       " 'rent': 480,\n",
       " 'bike': 481,\n",
       " 'tour': 482,\n",
       " 'bathtub': 483,\n",
       " 'meeting': 484,\n",
       " 'ca': 485,\n",
       " '30': 486,\n",
       " 'typical': 487,\n",
       " 'since': 488,\n",
       " 'most': 489,\n",
       " 'small': 490,\n",
       " 'buildings': 491,\n",
       " 'pay': 492,\n",
       " 'attention': 493,\n",
       " 'storeyed': 494,\n",
       " 'use': 495,\n",
       " 'east': 496,\n",
       " 'transport': 497,\n",
       " 'eat': 498,\n",
       " 'drink': 499,\n",
       " 'here': 500,\n",
       " 'again': 501,\n",
       " 'once': 502,\n",
       " 'fairly': 503,\n",
       " 'standard': 504,\n",
       " 'brit': 505,\n",
       " 'connoisseur': 506,\n",
       " 'cooked': 507,\n",
       " 'breakfasts': 508,\n",
       " 'disappointed': 509,\n",
       " 'hot': 510,\n",
       " 'generally': 511,\n",
       " 'everyone': 512,\n",
       " 'does': 513,\n",
       " 'english': 514,\n",
       " 'sit': 515,\n",
       " 'start': 516,\n",
       " 'least': 517,\n",
       " 'any': 518,\n",
       " 'worries': 519,\n",
       " 'due': 520,\n",
       " 'personally': 521,\n",
       " 'prefer': 522,\n",
       " 'wander': 523,\n",
       " 'explore': 524,\n",
       " 'dining': 525,\n",
       " 'experiences': 526,\n",
       " 'qualified': 527,\n",
       " 'give': 528,\n",
       " 'opinion': 529,\n",
       " 'certainly': 530,\n",
       " 'evenings': 531,\n",
       " 'suggests': 532,\n",
       " 'pretty': 533,\n",
       " 'staying': 534,\n",
       " 'next': 535,\n",
       " 'time': 536,\n",
       " 'take': 537,\n",
       " 'trip': 538,\n",
       " 'lines': 539,\n",
       " 'nicely': 540,\n",
       " 'localted': 541,\n",
       " 'accessed': 542,\n",
       " 'architecture': 543,\n",
       " 'anything': 544,\n",
       " 'although': 545,\n",
       " 'rather': 546,\n",
       " 'expensive': 547,\n",
       " '17': 548,\n",
       " '50': 549,\n",
       " 'per': 550,\n",
       " 'head': 551,\n",
       " 'expected': 552,\n",
       " 'hind': 553,\n",
       " 'sight': 554,\n",
       " 'further': 555,\n",
       " 'tourist': 556,\n",
       " 'might': 557,\n",
       " 'noisy': 558,\n",
       " 'courteous': 559,\n",
       " 'product': 560,\n",
       " 'proud': 561,\n",
       " 'work': 562,\n",
       " 'brunch': 563,\n",
       " 'purchase': 564,\n",
       " 'opening': 565,\n",
       " '2': 566,\n",
       " 'massive': 567,\n",
       " 'looks': 568,\n",
       " 'impressive': 569,\n",
       " 'd': 570,\n",
       " 'ever': 571,\n",
       " 'slept': 572,\n",
       " 'though': 573,\n",
       " 'under': 574,\n",
       " 'renovation': 575,\n",
       " 'disruption': 576,\n",
       " 'noise': 577,\n",
       " 'far': 578,\n",
       " 'trap': 579,\n",
       " 'situated': 580,\n",
       " 'bars': 581,\n",
       " 'cannot': 582,\n",
       " 'highly': 583,\n",
       " 'doing': 584,\n",
       " 'part': 585,\n",
       " 'given': 586,\n",
       " 'wish': 587,\n",
       " 'week': 588,\n",
       " 'night': 589,\n",
       " 'views': 590,\n",
       " 'space': 591,\n",
       " 'exquisite': 592,\n",
       " 'lot': 593,\n",
       " 'gigantic': 594,\n",
       " 'pillows': 595,\n",
       " 'bedsheets': 596,\n",
       " 'dark': 597,\n",
       " 'silent': 598,\n",
       " 'something': 599,\n",
       " 'impossible': 600,\n",
       " 'find': 601,\n",
       " 'accommodating': 602,\n",
       " 'over': 603,\n",
       " 'looking': 604,\n",
       " 'peaceful': 605,\n",
       " 'outskirts': 606,\n",
       " 'travel': 607,\n",
       " 'refurbishment': 608,\n",
       " 'suited': 609,\n",
       " 'perfectly': 610,\n",
       " 'mattress': 611,\n",
       " 'recepction': 612,\n",
       " 'sorted': 613,\n",
       " 'booking': 614,\n",
       " 'meal': 615,\n",
       " 'taxi': 616,\n",
       " 'me': 617,\n",
       " 'emailed': 618,\n",
       " 'them': 619,\n",
       " 'first': 620,\n",
       " 'booked': 621,\n",
       " 'online': 622,\n",
       " 'idea': 623,\n",
       " 'found': 624,\n",
       " 'best': 625,\n",
       " 'town': 626,\n",
       " 'draw': 627,\n",
       " 'needed': 628,\n",
       " 'subway': 629,\n",
       " 'hard': 630,\n",
       " 'down': 631,\n",
       " 'anywhere': 632,\n",
       " 'basically': 633,\n",
       " 'coffe': 634,\n",
       " 'order': 635,\n",
       " 'throuout': 636,\n",
       " 'honestly': 637,\n",
       " 'cares': 638,\n",
       " 'thumbs': 639,\n",
       " 'property': 640,\n",
       " 'thing': 641,\n",
       " 'experience': 642,\n",
       " 'keep': 643,\n",
       " 'surprise': 644,\n",
       " 'partners': 645,\n",
       " 'birthday': 646,\n",
       " 'got': 647,\n",
       " 'free': 648,\n",
       " 'upgrade': 649,\n",
       " 'arrival': 650,\n",
       " 'balloons': 651,\n",
       " 'delivery': 652,\n",
       " 'house': 653,\n",
       " 'him': 654,\n",
       " 'happy': 655,\n",
       " 'welcoming': 656,\n",
       " 'freebies': 657,\n",
       " 'open': 658,\n",
       " 'plenty': 659,\n",
       " 'touch': 660,\n",
       " 'accommodated': 661,\n",
       " 'fast': 662,\n",
       " 'politely': 663,\n",
       " 'begin': 664,\n",
       " 'made': 665,\n",
       " 'wife': 666,\n",
       " 'warm': 667,\n",
       " 'minimal': 668,\n",
       " 'improved': 669,\n",
       " 'looked': 670,\n",
       " 'undergone': 671,\n",
       " 'major': 672,\n",
       " 'last': 673,\n",
       " 'wing': 674,\n",
       " 'company': 675,\n",
       " 'invested': 676,\n",
       " 'impressed': 677,\n",
       " 'nature': 678,\n",
       " 'comes': 679,\n",
       " 'together': 680,\n",
       " 'magnificent': 681,\n",
       " 'preferred': 682,\n",
       " 'dinner': 683,\n",
       " 'seeing': 684,\n",
       " 'quick': 685,\n",
       " 'leidseplein': 686,\n",
       " 'refebishment': 687,\n",
       " 'moment': 688,\n",
       " 'am': 689,\n",
       " 'forward': 690,\n",
       " 'complete': 691,\n",
       " 'see': 692,\n",
       " 'final': 693,\n",
       " 'look': 694,\n",
       " 'think': 695,\n",
       " 'then': 696,\n",
       " 'already': 697,\n",
       " 'stylish': 698,\n",
       " 'receptionist': 699,\n",
       " 'young': 700,\n",
       " 'guy': 701,\n",
       " 'reception': 702,\n",
       " 'ran': 703,\n",
       " 'batch': 704,\n",
       " 'undercooked': 705,\n",
       " 'limited': 706,\n",
       " 'choice': 707,\n",
       " 'cereal': 708,\n",
       " 'bread': 709,\n",
       " 'much': 710,\n",
       " 'yogurt': 711,\n",
       " 'tomatoes': 712,\n",
       " 'added': 713,\n",
       " 'healpful': 714,\n",
       " 'dinning': 715,\n",
       " 'rest': 716,\n",
       " 'hints': 717,\n",
       " 'age': 718,\n",
       " 'works': 719,\n",
       " 'exactly': 720,\n",
       " 'lobby': 721,\n",
       " 'environment': 722,\n",
       " 'funky': 723,\n",
       " 'designed': 724,\n",
       " 'requested': 725,\n",
       " 'arrived': 726,\n",
       " 'self': 727,\n",
       " 'walkable': 728,\n",
       " 'easily': 729,\n",
       " 'times': 730,\n",
       " 'fab': 731,\n",
       " 'extra': 732,\n",
       " '065': 733,\n",
       " 'ready': 734,\n",
       " 'early': 735,\n",
       " 'backs': 736,\n",
       " 'straight': 737,\n",
       " 'wait': 738,\n",
       " 'construction': 739,\n",
       " 'didn': 740,\n",
       " 'hear': 741,\n",
       " 'related': 742,\n",
       " 'whilst': 743,\n",
       " 'atmosphere': 744,\n",
       " 'feeling': 745,\n",
       " 'especially': 746,\n",
       " 'hall': 747,\n",
       " 'still': 748,\n",
       " 'course': 749,\n",
       " 'parc': 750,\n",
       " 'opened': 751,\n",
       " 'days': 752,\n",
       " 'before': 753,\n",
       " 'burger': 754,\n",
       " 'fresh': 755,\n",
       " 'orange': 756,\n",
       " 'juice': 757,\n",
       " 'grand': 758,\n",
       " 'chatty': 759,\n",
       " 'completed': 760,\n",
       " 'fabulous': 761,\n",
       " 'venue': 762,\n",
       " 'keen': 763,\n",
       " 'summer': 764,\n",
       " 'gloss': 765,\n",
       " 'absolutely': 766,\n",
       " 'interesting': 767,\n",
       " 'changed': 768,\n",
       " 'quickly': 769,\n",
       " 'complain': 770,\n",
       " 'cold': 771,\n",
       " 'strong': 772,\n",
       " 'paint': 773,\n",
       " 'card': 774,\n",
       " 'inconveniences': 775,\n",
       " 'normal': 776,\n",
       " 'chain': 777,\n",
       " 'should': 778,\n",
       " 'say': 779,\n",
       " 'finished': 780,\n",
       " 'cheap': 781,\n",
       " 'anyways': 782,\n",
       " 'complants': 783,\n",
       " '1km': 784,\n",
       " 'nearest': 785,\n",
       " 'tidy': 786,\n",
       " 'sleep': 787,\n",
       " 'several': 788,\n",
       " 'faulty': 789,\n",
       " 'details': 790,\n",
       " 'unfinished': 791,\n",
       " 'lamp': 792,\n",
       " 'nails': 793,\n",
       " 'sticking': 794,\n",
       " 'rips': 795,\n",
       " 'sock': 796,\n",
       " 'etc': 797,\n",
       " 'nothing': 798,\n",
       " 'adding': 799,\n",
       " 'makes': 800,\n",
       " 'three': 801,\n",
       " 'star': 802,\n",
       " 'opinnion': 803,\n",
       " 'beautifull': 804,\n",
       " 'buiding': 805,\n",
       " 'decor': 806,\n",
       " 'staircases': 807,\n",
       " 'want': 808,\n",
       " 'avoid': 809,\n",
       " 'hectic': 810,\n",
       " 'red': 811,\n",
       " 'light': 812,\n",
       " 'district': 813,\n",
       " 'walked': 814,\n",
       " 'half': 815,\n",
       " 'hour': 816,\n",
       " 'immediate': 817,\n",
       " 'local': 818,\n",
       " 'frequented': 819,\n",
       " 'locals': 820,\n",
       " 'largest': 821,\n",
       " 'beer': 822,\n",
       " 'available': 823,\n",
       " 'brewery': 824,\n",
       " 'tours': 825,\n",
       " 'heineken': 826,\n",
       " 'museum': 827,\n",
       " 'coffeeshop': 828,\n",
       " 'better': 829,\n",
       " 'value': 830,\n",
       " 'larger': 831,\n",
       " 'infront': 832,\n",
       " 'allowed': 833,\n",
       " 'relax': 834,\n",
       " 'nights': 835,\n",
       " 've': 836,\n",
       " 'probably': 837,\n",
       " 'comfort': 838,\n",
       " 'managed': 839,\n",
       " 'identy': 840,\n",
       " 'despite': 841,\n",
       " 'moderisation': 842,\n",
       " 'extrememly': 843,\n",
       " 'cleanliness': 844,\n",
       " 'outstanding': 845,\n",
       " 'world': 846,\n",
       " 'pleasant': 847,\n",
       " 'jogger': 848,\n",
       " 'stroll': 849,\n",
       " 'actually': 850,\n",
       " 'heaven': 851,\n",
       " 'cozy': 852,\n",
       " 'sweet': 853,\n",
       " 'attentive': 854,\n",
       " 'customer': 855,\n",
       " 'responsive': 856,\n",
       " 'individual': 857,\n",
       " 'needs': 858,\n",
       " 'giving': 859,\n",
       " 'directions': 860,\n",
       " 'passes': 861,\n",
       " 'selections': 862,\n",
       " 'water': 863,\n",
       " 'pressure': 864,\n",
       " 'parks': 865,\n",
       " 'kind': 866,\n",
       " 'vibe': 867,\n",
       " 'interestingly': 868,\n",
       " 'worn': 869,\n",
       " 'meanwhile': 870,\n",
       " 'underway': 871,\n",
       " 'nicer': 872,\n",
       " 'meantime': 873,\n",
       " 'wooden': 874,\n",
       " 'ramp': 875,\n",
       " 'process': 876,\n",
       " 'other': 877,\n",
       " 'similar': 878,\n",
       " 'properties': 879,\n",
       " 'possibly': 880,\n",
       " 'beaten': 881,\n",
       " 'path': 882,\n",
       " 'bad': 883,\n",
       " 'neighborhood': 884,\n",
       " 'spots': 885,\n",
       " 'architecturally': 886,\n",
       " 'terrific': 887,\n",
       " 'isn': 888,\n",
       " 'purpose': 889,\n",
       " 'built': 890,\n",
       " 'arena': 891,\n",
       " 'boutique': 892,\n",
       " 'lushly': 893,\n",
       " 'wrought': 894,\n",
       " 'iron': 895,\n",
       " 'chandeliers': 896,\n",
       " 'lighting': 897,\n",
       " 'windows': 898,\n",
       " 'ceilings': 899,\n",
       " 'gives': 900,\n",
       " 'sense': 901,\n",
       " 'green': 902,\n",
       " 'ten': 903,\n",
       " 'min': 904,\n",
       " 'halls': 905,\n",
       " 'footprint': 906,\n",
       " 'ground': 907,\n",
       " 'closet': 908,\n",
       " 'sofa': 909,\n",
       " 'wc': 910,\n",
       " 'table': 911,\n",
       " 'mezzanine': 912,\n",
       " 'tv': 913,\n",
       " 'each': 914,\n",
       " 'money': 915,\n",
       " 'attractions': 916,\n",
       " 'neighbourhood': 917,\n",
       " 'zoo': 918,\n",
       " 'accessible': 919,\n",
       " 'outstandingly': 920,\n",
       " 'classy': 921,\n",
       " 'sinks': 922,\n",
       " 'showers': 923,\n",
       " 'sitting': 924,\n",
       " 'bedroom': 925,\n",
       " 'door': 926,\n",
       " '20': 927,\n",
       " 'canal': 928,\n",
       " 'wake': 929,\n",
       " 'beautifully': 930,\n",
       " 'voucher': 931,\n",
       " 'compensate': 932,\n",
       " 'liking': 933,\n",
       " 'fine': 934,\n",
       " 'plentiful': 935,\n",
       " 'often': 936,\n",
       " 'meant': 937,\n",
       " 'sausage': 938,\n",
       " 'services': 939,\n",
       " 'willing': 940,\n",
       " 'don': 941,\n",
       " 'mind': 942,\n",
       " 'taking': 943,\n",
       " 'potential': 944,\n",
       " 'while': 945,\n",
       " 'extention': 946,\n",
       " 'priority': 947,\n",
       " 'frayed': 948,\n",
       " 'edges': 949,\n",
       " 'visiting': 950,\n",
       " 'relatives': 951,\n",
       " 'ambience': 952,\n",
       " 'convent': 953,\n",
       " 'medical': 954,\n",
       " 'institution': 955,\n",
       " 'converted': 956,\n",
       " 'relaxed': 957,\n",
       " 'terasse': 958,\n",
       " 'accessibility': 959,\n",
       " 'size': 960,\n",
       " 'links': 961,\n",
       " 'baked': 962,\n",
       " 'croissants': 963,\n",
       " 'snacks': 964,\n",
       " 'cheerful': 965,\n",
       " 'duck': 966,\n",
       " 'feather': 967,\n",
       " 'duvet': 968,\n",
       " 'deluxe': 969,\n",
       " 'proximity': 970,\n",
       " 'provision': 971,\n",
       " 'board': 972,\n",
       " 'televisions': 973,\n",
       " 'long': 974,\n",
       " 'round': 975,\n",
       " 'drinks': 976,\n",
       " 'consolation': 977,\n",
       " 'live': 978,\n",
       " 'suite': 979,\n",
       " 'speak': 980,\n",
       " 'pity': 981,\n",
       " 'club': 982,\n",
       " 'sandwiches': 983,\n",
       " 'lunch': 984,\n",
       " 'awful': 985,\n",
       " 'unusual': 986,\n",
       " 'hospital': 987,\n",
       " 'reasonably': 988,\n",
       " 'convienent': 989,\n",
       " 'beside': 990,\n",
       " 'side': 991,\n",
       " 'basrs': 992,\n",
       " 'asked': 993,\n",
       " 'move': 994,\n",
       " 'gothic': 995,\n",
       " 'thai': 996,\n",
       " 'ongoing': 997,\n",
       " 'never': 998,\n",
       " 'know': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assign_ids_to_words(vocab):\n",
    "    # Stores the integer token for each unique word in the vocabulary\n",
    "    ids_vocab = {}\n",
    "\n",
    "    id = 0\n",
    "    # Assigns words in the vocabulary to integer tokens\n",
    "    for word, v in vocabulary.items():\n",
    "        ids_vocab[word] = id\n",
    "        id += 1\n",
    "    \n",
    "    return ids_vocab\n",
    "\n",
    "ids_vocab = assign_ids_to_words(vocabulary)\n",
    "ids_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecc5458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def tokenize(corpus, ids_vocab):\n",
    "    \"\"\"\n",
    "        Converts words in the dataset to integer tokens\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_corpus = []\n",
    "    for line, sentiment in corpus:\n",
    "        new_line = []\n",
    "        for i, word in enumerate(line):\n",
    "            if word in ids_vocab and (i == 0 or word != line[i-1]):\n",
    "                new_line.append(ids_vocab[word])\n",
    "\n",
    "        new_line = torch.Tensor(new_line).long()\n",
    "        tokenized_corpus.append((new_line, sentiment))\n",
    "\n",
    "    return tokenized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29d14f",
   "metadata": {},
   "source": [
    "### Put your test set here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ea1f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_corpus = tokenize(data_set, ids_vocab)\n",
    "#token_corpus_test = tokenize(test_set, ids_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9dfadea",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 300\n",
    "\n",
    "embeds = torch.zeros(len(ids_vocab) + 1, emb_dim)\n",
    "\n",
    "for token, idx in ids_vocab.items():\n",
    "    embeds[idx] = global_vectors[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fc2a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_indices_tokenized(num_values, percentage):\n",
    "\n",
    "    # Determine size of Validation set\n",
    "    val_size = int(percentage * num_values)\n",
    "\n",
    "    # Create random permutation of 0 to num_values-1\n",
    "    idxs = np.random.permutation(num_values)\n",
    "    return np.sort(idxs[val_size:]), np.sort(idxs[:val_size])\n",
    "\n",
    "set_seed(1)\n",
    "train_pos_indices, val_pos_indices = split_indices_tokenized(len(positive_data), 0.1)\n",
    "train_neg_indices, val_neg_indices = split_indices_tokenized(len(negative_data), 0.1)\n",
    "\n",
    "train_indices = np.concatenate((train_pos_indices, train_neg_indices+len(positive_data)-1))\n",
    "val_indices = np.concatenate((val_pos_indices, val_neg_indices+len(positive_data)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b4701fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# ----------- Batching the data -----------\n",
    "def collate_fn_tokens(instn):\n",
    "\n",
    "    sentence = [x[0] for x in instn]\n",
    "\n",
    "    # Pre padding\n",
    "    sen_len = [len(x[0]) for x in instn]\n",
    "    max_len = max(sen_len)\n",
    "\n",
    "    padded_sent = torch.zeros(1, max_len)\n",
    "    sentence_pad = [torch.cat((torch.zeros(max_len-len(x[0])), x[0]), dim=0) for x in instn]\n",
    "    \n",
    "    for i in sentence_pad:\n",
    "        padded_sent = torch.cat((padded_sent, i.unsqueeze(dim=0)), dim=0)\n",
    "    padded_sent = padded_sent[1:].long()\n",
    "\n",
    "    # Post padding\n",
    "    #padded_sent = pad_sequence(sentence, batch_first=True, padding_value=0)\n",
    "\n",
    "    labels = torch.Tensor([x[1] for x in instn])\n",
    "\n",
    "    return (padded_sent, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02827c06",
   "metadata": {},
   "source": [
    "#### Setting Up Batch-Size and Preparing DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "966228aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_sampler   = SubsetRandomSampler(train_indices)\n",
    "train_loader    = DataLoader(token_corpus, batch_size, sampler=train_sampler, collate_fn=collate_fn_tokens)\n",
    "\n",
    "val_sampler     = SubsetRandomSampler(val_indices)\n",
    "val_loader      = DataLoader(token_corpus, batch_size, sampler=val_sampler, collate_fn=collate_fn_tokens)\n",
    "\n",
    "#test_loader      = DataLoader(token_corpus_test, batch_size, collate_fn=collate_fn_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31f6f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile model.py\n",
    "# Models\n",
    "class BILSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, embeds):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embeds, padding_idx=0)\n",
    "\n",
    "        self.lstm = nn.GRU(input_size = 300, hidden_size = 128, num_layers = 2, batch_first = True, bidirectional = True, dropout=0.5)\n",
    "\n",
    "        self.lin1 = nn.Linear(256, 64)\n",
    "        self.lin2 = nn.Linear(64, 1)\n",
    "\n",
    "        self.lin3 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, xb, tsne = False):\n",
    "\n",
    "        xe = self.embeddings(xb)\n",
    "        out, y = self.lstm(xe)\n",
    "        \n",
    "        x = self.lin3(out).squeeze(dim=-1)\n",
    "        x = torch.softmax(x, dim=-1).unsqueeze(dim=1)\n",
    "        x = torch.bmm(x, out).squeeze(dim=1)\n",
    "\n",
    "        #x = torch.cat((x, y[2][ :, :], y[3][ :, :]), dim = 1)\n",
    "        x = self.lin1(x)\n",
    "\n",
    "        if tsne == True:\n",
    "            return x \n",
    "\n",
    "        x = F.relu(x)\n",
    "        x = self.lin2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class DAN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(600, 1024)\n",
    "        self.linear2 = nn.Linear(1024, 2048)\n",
    "        self.linear3 = nn.Linear(2048, 512)\n",
    "        self.linear4 = nn.Linear(512, 64)\n",
    "        self.linear5 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, Xb, tsne = False):\n",
    "        x = self.linear1(Xb)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x) \n",
    "        x = self.linear3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear4(x)\n",
    "        \n",
    "        if tsne == True:\n",
    "            return x\n",
    "            \n",
    "        x = F.relu(x)\n",
    "        x = self.linear5(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "953ea28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BILSTM(embeds)\n",
    "model.to(device)\n",
    "opt_c = torch.optim.AdamW(model.parameters(), lr = 0.001)\n",
    "# loss_fn_c = F.cross_entropy - Tried Cross Entropy with log_softmax output function - gave similar results\n",
    "loss_fn_c = F.binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71977f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 203.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1  Training Loss:  0.23932505290456643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 508.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.17141033413595166\n",
      "Validation accuracy:  94.04894327030033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 219.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2  Training Loss:  0.14603124300795278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 515.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.14707348251651073\n",
      "Validation accuracy:  95.05005561735261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 218.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3  Training Loss:  0.1302900196559082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 506.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.13913201832951144\n",
      "Validation accuracy:  95.32814238042269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 217.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4  Training Loss:  0.11335727973569801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 510.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.13429802090957246\n",
      "Validation accuracy:  95.38375973303671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 219.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5  Training Loss:  0.10090932731817323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 507.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.14923556110468403\n",
      "Validation accuracy:  95.93993325917687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 177.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6  Training Loss:  0.09056226234501741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 519.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.13535386741418262\n",
      "Validation accuracy:  95.99555061179088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 220.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7  Training Loss:  0.08205752281882749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 499.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.1623255149300756\n",
      "Validation accuracy:  95.7174638487208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 218.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8  Training Loss:  0.06779209773723535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 496.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.18775305286820593\n",
      "Validation accuracy:  95.43937708565072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 219.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9  Training Loss:  0.06256012497176452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 504.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.1644036403760828\n",
      "Validation accuracy:  95.43937708565072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 217.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10  Training Loss:  0.052708608815153164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 497.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.1731012019103971\n",
      "Validation accuracy:  95.93993325917687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 220.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11  Training Loss:  0.05327751270796018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 512.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.16981239432212095\n",
      "Validation accuracy:  95.55061179087876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 218.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12  Training Loss:  0.04451086304396185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 515.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.1672535389501216\n",
      "Validation accuracy:  95.7174638487208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 216.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13  Training Loss:  0.04318502820766069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 503.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.20752392073386702\n",
      "Validation accuracy:  95.66184649610679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 218.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  14  Training Loss:  0.03940076361764149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 508.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.19722509606147248\n",
      "Validation accuracy:  95.7174638487208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 218.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  15  Training Loss:  0.03959109205578446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 504.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.2441439611901497\n",
      "Validation accuracy:  95.32814238042269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 217.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16  Training Loss:  0.03099389144427539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 501.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.22822238866175557\n",
      "Validation accuracy:  95.66184649610679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 220.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  17  Training Loss:  0.028994814148672315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 495.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.22518126875290584\n",
      "Validation accuracy:  95.16129032258065\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 216.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  18  Training Loss:  0.032031872350907944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 509.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.23931368119243918\n",
      "Validation accuracy:  95.05005561735261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 218.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19  Training Loss:  0.030968145021846093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 505.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.21982175927480746\n",
      "Validation accuracy:  94.93882091212458\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 217.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  20  Training Loss:  0.03098137669199271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 97.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.20668450349857548\n",
      "Validation accuracy:  95.05005561735261\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 217.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  21  Training Loss:  0.026198359035247913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 505.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.25555669676142034\n",
      "Validation accuracy:  95.27252502780867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 219.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  22  Training Loss:  0.0276594963707314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 505.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.24670754801251138\n",
      "Validation accuracy:  95.55061179087876\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 216.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  23  Training Loss:  0.023509343466892776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 510.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.33942719269543886\n",
      "Validation accuracy:  95.66184649610679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 216.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  24  Training Loss:  0.02688264629302187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 493.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.26874658218103237\n",
      "Validation accuracy:  95.05005561735261\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 254/254 [00:01<00:00, 217.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  25  Training Loss:  0.028372334635254605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 507.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  0.26267409530179253\n",
      "Validation accuracy:  94.93882091212458\n",
      "Saving Model\n"
     ]
    }
   ],
   "source": [
    "# ----------- Main Training Loop -----------\n",
    "max_epoch = 25\n",
    "\n",
    "best_test_acc = 0\n",
    "for ep in range(max_epoch):\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for xb, yb in tqdm(train_loader):\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        y_hat = model(xb)\n",
    "        loss = loss_fn_c(y_hat.squeeze(), yb)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        opt_c.step()\n",
    "\n",
    "        opt_c.zero_grad()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "\n",
    "        epoch_loss += float(loss)\n",
    "\n",
    "    print(\"Epoch: \", ep+1, \" Training Loss: \", epoch_loss/len(train_loader))\n",
    "\n",
    "\n",
    "    #----------- Validation -----------\n",
    "\n",
    "    val_labels = []\n",
    "    val_pred = []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in tqdm(val_loader):\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            y_hat = model(xb)\n",
    "            loss = loss_fn_c(y_hat.squeeze(), yb)\n",
    "\n",
    "            val_epoch_loss += float(loss)\n",
    "\n",
    "            val_labels.extend(torch.round(yb).cpu().detach().numpy())\n",
    "            val_pred.extend(y_hat.round().cpu().detach().numpy())\n",
    "\n",
    "    print(\"Validation loss: \", val_epoch_loss/len(val_loader))\n",
    "    print(\"Validation accuracy: \", accuracy_score(val_labels, val_pred)*100)\n",
    "\n",
    "    if ep > 15 and prev_val_loss - val_epoch_loss > 0.05:\n",
    "        print(\"Saving Model\")\n",
    "        torch.save(model.state_dict(), \"GRU_model.pt\")\n",
    "    \n",
    "    prev_val_loss = val_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eec5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
